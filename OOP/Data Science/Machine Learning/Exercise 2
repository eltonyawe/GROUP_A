# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


# Load the dataset
data = pd.read_csv(' local data.csv') # Replace 'loan_data.csv' with your dataset path


# Preprocess the data
# Assuming the target column is named 'Loan_Status'
# and all other columns are features


# Handle missing values if necessary
data.fillna(method='ffill', inplace=True)


# Convert categorical variables
data = pd.get_dummies(data)


# Split the data into features (X) and target (y)
X = data.drop('Loan_Status', axis=1)
y = data['Loan_Status']


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Standardize the feature variables
scaler = StandardScaler()
X_train = scale.fit_transform(X_train)
X_test = scaler.transform(X_test)


# Train a Random Forest classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)


# Make predictions on the test set
y_pred = model.predict(X_test)


# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)


print(f'Accuracy: {accuracy}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classfication Report:')
print(class_report)